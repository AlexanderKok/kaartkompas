# Feature Plan: URL-Based Menu Parsing and Restaurant Database

## Feature Description

Add a URL parsing feature to the MenuInsights dashboard that can extract menu data from restaurant URLs. The system will support multiple parsing strategies for different document types (digital PDFs, scanned PDFs, HTML/web menus, JavaScript-rendered content) and create comprehensive restaurant records with detailed menu item information including visual prominence indicators.

Key requirements from user:
- Add "Upload URL" field to menu-insights dashboard upload tab  
- Parse menu items and save to database with price, name, description, prominence on menu
- Capture prominence through standardized coding of font size, chef's special/customer favorite icons, visual markers like boxes
- Create restaurant table with Location (Address or city), URL, Restaurant Type (dropdown: Casual dining, Fine dining, Fast casual, QSR, Café, etc.), Cuisine(s)
- Test pipeline with first 20 URLs from provided CSV file
- Separate parsing strategies for each document type to keep task achievable

## Files and Functions to Change/Create

### Database Schema Changes

**New file: `/server/src/schema/restaurants.ts`**
- Create `restaurants` table with fields: id, name, url, address, city, country, restaurantType, cuisines[], latitude, longitude, phoneNumber, description, createdAt, updatedAt
- Create `restaurantMenuSources` table linking restaurants to menu URLs with source type (pdf, html, js)

**Modify: `/server/src/schema/menus.ts`**
- Add `restaurantId` foreign key to `menuUploads` table
- Add `sourceUrl` field to track original URL
- Add `parseMethod` field to track which parsing strategy was used
- Add `prominence` JSON field to `menuItems` table for storing visual indicators:
  - fontSize (small/medium/large/xlarge)
  - hasSpecialIcon (boolean)
  - iconType (chef_special/customer_favorite/new/spicy/etc)
  - hasVisualBox (boolean)
  - isHighlighted (boolean)
  - position (object with x,y coordinates if extractable)

### API Endpoints

**Modify: `/server/src/api.ts`**
- Add `POST /api/v1/protected/restaurants` - create restaurant record
- Add `POST /api/v1/protected/menus/parse-url` - initiate URL parsing
- Add `GET /api/v1/protected/restaurants` - list user's restaurants
- Add `GET /api/v1/protected/restaurants/:id/menus` - get restaurant's menus
- Modify existing menu endpoints to handle URL-based uploads

### Parsing Service Layer

**New file: `/server/src/services/urlParser.ts`**
- `detectDocumentType(url: string)` - determine parsing strategy needed
- `parseUrl(url: string, strategy: ParseStrategy)` - main parsing orchestrator
- `validateRestaurantUrl(url: string)` - basic URL validation

**New file: `/server/src/services/parsers/pdfParser.ts`**
- `parseDigitalPdf(url: string)` - extract text from digital PDFs
- `parseScannedPdf(url: string)` - OCR for scanned PDFs using library like Tesseract
- `extractPdfMenuItems(text: string)` - parse menu structure from PDF text

**New file: `/server/src/services/parsers/htmlParser.ts`**
- `parseHtmlMenu(url: string)` - extract menu from HTML pages
- `detectMenuSelectors(html: string)` - identify menu containers
- `extractMenuStructure(elements: Element[])` - parse menu items and categories

**New file: `/server/src/services/parsers/jsParser.ts`**
- `parseJavaScriptMenu(url: string)` - handle SPA/dynamic content using Puppeteer
- `waitForMenuLoad(page: Page)` - wait for menu content to render
- `extractDynamicMenu(page: Page)` - extract from JS-rendered content

**New file: `/server/src/services/parsers/menuItemExtractor.ts`**
- `extractMenuItems(content: any, contentType: string)` - unified menu item extraction
- `detectProminence(element: any)` - analyze visual prominence indicators
- `standardizePrice(priceText: string)` - normalize price formats
- `categorizeMenuItem(item: any)` - determine menu categories

### Frontend Components

**Modify: `/ui/src/pages/MenuInsights.tsx`**
- Add "Upload URL" input field to upload tab
- Add restaurant type dropdown with options: Casual dining, Fine dining, Fast casual, QSR, Café, etc.
- Add cuisine selection (multi-select)
- Add location fields (address/city)
- Update handleFileUpload to handle URL submissions

**New file: `/ui/src/components/UrlUpload.tsx`**
- URL input field with validation
- Restaurant information form
- Parsing progress indicator
- Error handling for failed parses

**Modify: `/ui/src/lib/serverComm.ts`**
- Add `uploadMenuUrl(urlData: UrlUploadData)` function
- Add `getRestaurants()` function
- Add types for restaurant and URL upload data

### Processing Queue System

**New file: `/server/src/services/parseQueue.ts`**
- Background job processing for URL parsing
- Queue management with retry logic
- Status tracking for long-running parses

## Parsing Strategy Algorithms

### Phase 1: Document Type Detection
1. Fetch URL headers to check content-type
2. If PDF: determine if digital (text-extractable) or scanned (image-based)
3. If HTML: check for dynamic content indicators (React, Vue, Angular frameworks)
4. If JavaScript detected: flag for browser-based parsing
5. Store detection results in database for future optimization

### Phase 2A: Digital PDF Parsing
1. Download PDF using HTTP request
2. Extract text using PDF parsing library (pdf-parse)
3. Identify menu sections using regex patterns for categories
4. Extract items using patterns for name/price combinations
5. Detect prominence through font size analysis and formatting

### Phase 2B: Scanned PDF Parsing  
1. Convert PDF pages to images
2. Run OCR using Tesseract.js or cloud OCR service
3. Post-process OCR text for common errors
4. Apply same menu extraction logic as digital PDFs
5. Lower confidence scores due to OCR uncertainty

### Phase 2C: HTML Menu Parsing
1. Fetch HTML content using HTTP request
2. Parse DOM using Cheerio
3. Identify menu containers through common selectors (.menu, .food, .items)
4. Extract items from structured HTML (lists, tables, divs)
5. Analyze CSS classes/styles for prominence indicators

### Phase 2D: JavaScript Menu Parsing
1. Launch headless browser using Puppeteer
2. Navigate to URL and wait for content load
3. Execute JavaScript and wait for menu rendering
4. Extract rendered DOM content
5. Apply HTML parsing logic to extracted content
6. Handle infinite scroll and lazy loading

### Phase 3: Menu Item Standardization
1. Normalize price formats (remove currency symbols, handle ranges)
2. Clean item names (remove special characters, standardize capitalization)
3. Extract descriptions from combined name/description fields
4. Categorize items using keyword matching and ML classification
5. Score prominence based on visual indicators:
   - Font size: Extract from CSS computed styles or font tags
   - Special icons: Detect through alt text, CSS classes, or image analysis
   - Visual boxes: Identify through border/background styling
   - Position: Track DOM order and CSS positioning

## Testing Strategy

Use provided CSV file (`docs/temp_files/combined_restaurants_20250806_200450.csv`) to test first 20 URLs:
1. Create test script that iterates through restaurants. Add all restaurants to the restaurantMenuSources table so we can work from there for future tests
2. For each URL, attempt all applicable parsing strategies. 
3. Log success/failure rates and parsing confidence
4. Store extracted data for manual verification
5. Generate report comparing extraction results across different methods

## Database Migration Requirements

1. Create new `restaurants` table
2. Create `restaurant_menu_sources` junction table  
3. Add columns to existing `menu_uploads` table:
   - `restaurant_id` (foreign key)
   - `source_url` (text)
   - `parse_method` (text)
4. Add `prominence` JSON column to `menu_items` table
5. Create indexes on restaurant lookups and URL sources

## Implementation Phases

### Phase 1: Data Layer (Foundation)
- Create restaurant and menu source tables
- Update existing menu schema with new fields
- Run database migrations
- Define TypeScript types for all new entities

### Phase 2A: Basic URL Upload UI  
- Add URL input field to MenuInsights upload tab
- Add restaurant information form
- Integrate with existing upload flow
- Basic validation and error handling

### Phase 2B: HTML Parser Implementation
- Implement HTML menu parsing (simplest strategy)
- Build menu item extraction and prominence detection
- Test with HTML-based restaurants from restaurantMenuSources
- Create background job processing

### Phase 2C: PDF Parser Implementation  
- Implement digital PDF parsing
- Add OCR capability for scanned PDFs
- Test with PDF-based menu URLs from restaurantMenuSources
- Integrate with job queue system

### Phase 2D: JavaScript Parser Implementation
- Implement Puppeteer-based parsing for dynamic content
- Handle SPA frameworks and lazy loading
- Test with JavaScript-heavy restaurant sites
- Optimize for performance and reliability

### Phase 3: Testing and Optimization
- Run automated tests on first 40 restaurantMenuSources URLs  
- Analyze parsing success rates and accuracy
- Refine extraction algorithms based on results
- Add monitoring and error reporting