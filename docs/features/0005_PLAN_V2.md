## Feature 0005: Unified PDF Processing Architecture (V2 Plan)

### Context

- Phase 1 completed: authenticated upload endpoint wired to dashboard and reusing the public parsing logic for fast iteration.
- Small review fixes applied:
  - Enforce `email` in dev token parsing to avoid `users.email` null conflicts.
  - Strip raw base64 `fileContent` from menu responses to reduce payload size and exposure.
  - Remove duplicate `users` import in `menus` schema.

This V2 plan focuses on delivering the unified pipeline (triage, storage, documents/state machine, queue split) and real parsing, while keeping current UI flows working.

### Objectives (high level)

- Unify URL/file inputs under a single document triage entry point.
- Move raw file bytes out of DB JSON blobs into a proper file storage layer.
- Introduce `documents` and processing lineage tables; add a state machine for status.
- Split parsing and analysis into separate jobs.
- Implement layout-aware digital PDF parsing with OCR fallback.
- Migrate public endpoints to the unified pipeline without breaking current FE.

---

## Phase 2: Document Triage + File Storage + Documents Schema

### Deliverables

1) Document Triage Service
- File: `server/src/services/documentTriage.ts` (new)
- Purpose: Unified entry point that detects document type and returns routing info.
- API:
```ts
export interface DocumentInput {
  type: 'url' | 'file';
  source: string | { content: string; mimeType: string; fileName?: string };
  userId?: string;
  restaurantId?: string;
}

export interface DocumentTriageResult {
  documentId: string;
  documentType: DocumentType; // 'digital_pdf' | 'scanned_pdf' | 'html_static' | 'html_dynamic'
  processingStrategy: ParseStrategy; // 'pdf_digital' | 'pdf_ocr' | 'html' | 'javascript'
  storagePath: string; // local path or external URL
  contentAnalysis: {
    textRatio?: number;
    pageCount?: number;
    hasImages?: boolean;
    confidence: number;
  };
}
```
- Detection outline:
  - If `mimeType === application/pdf`:
    - Use `pdfinfo` for page metadata; `pdftotext -f 1 -l 1` for first-page text.
    - If text ratio < 0.3 → `scanned_pdf`, else `digital_pdf`.
  - If HTML: inspect for `<script>` to differentiate static vs. dynamic.

2) File Storage Service
- File: `server/src/services/fileStorage.ts` (new)
- Implementation: local filesystem first, e.g. `server/uploads/documents/{userId}/{documentId}.pdf`.
- API:
```ts
export async function storeDocument(contentBase64: string, userId: string, filename: string): Promise<string>; // returns storagePath
export async function retrieveDocument(storagePath: string): Promise<Buffer>;
```
- Notes:
  - Ensure directory creation and safe filenames.
  - Add `server/uploads/` to `.gitignore` if not present.
  - Enforce max file size (see Non-functional section).

3) Documents + Lineage Tables
- File: `server/src/schema/documents.ts` (new)
- Tables (Drizzle): `documents`, `parse_runs`, `analysis_runs` per V1 plan, with indexes on `documents.userId`, `documents.status`, `documents.sourceType`.
- Wire into Drizzle config and include a migration file.

4) API Integration (minimal)
- Add helper to create a `documents` record when triage is invoked, and persist `storagePath` from File Storage.
- Do not return raw bytes in API responses. Persist only `storagePath` + metadata.

### Dependencies and Setup

- Parsing utilities (system): install Poppler tools for dev
  - macOS: `brew install poppler` (provides `pdfinfo`, `pdftotext`, `pdftoppm`)
- Node packages for later phases (can be added now or in Phase 4):
  - `pnpm add pdfjs-dist tesseract.js`

### Acceptance criteria

- Given a file upload or URL, triage stores the bytes (if upload), creates a `documents` record, returns detected `documentType` and `processingStrategy`.
- No API returns include raw `fileContent`.
- New tables are migrated and accessible; indexes exist as defined.
- Upload size limit enforced; large files rejected with 413.

---

## Phase 3: State Machine + Queue Separation

### Deliverables

1) State Machine
- File: `server/src/services/stateMachine.ts` (new)
- `DocumentStatus` and `validTransitions` as defined previously.
- `transitionDocumentStatus(documentId, newStatus, reason?)` that validates and updates.

2) Parse Queue (focus solely on parsing)
- File: `server/src/services/parseQueue.ts` (refactor)
- Replace restaurant-source coupling with `documents` + `parse_runs`.
- Methods:
  - `enqueueParseJob(documentId: string, parserVersion: string): Promise<string>`
  - `processParseJob(job: ParseJob): Promise<void>`
- Status flow: `queued` → `parsing` → `parsed` (via state machine).
- Persist raw parsing output to `parse_runs.rawOutput`.

3) Analysis Queue (new)
- File: `server/src/services/analysisQueue.ts` (new)
- Input: `parseRunId`; reads `parse_runs.rawOutput`, produces structured menu analysis.
- Status flow: `parsed` → `analyzing` → `analyzed` → `done`.

4) Types update
- File: `server/src/types/url-parsing.ts` (extend)
```ts
export interface ParseJob {
  id: string;
  documentId: string;
  runId: string;
  inputType: 'url' | 'file';
  inputSource: string; // URL or file path
  parserVersion: string;
  createdAt: Date;
  userId?: string;
  restaurantId?: string;
}

export interface AnalysisJob {
  id: string;
  parseRunId: string;
  analysisVersion: string;
  createdAt: Date;
}
```

### Acceptance criteria

- New state machine blocks invalid transitions and updates persistently.
- Parse and analysis run as separate queues with independent retry logic.
- Raw parse output stored only in `parse_runs`; structured analysis stored only in `analysis_runs`.

---

## Phase 4: Layout-Aware Parsing + OCR Fallback

### Deliverables

1) Digital PDF Parser (layout-aware)
- File: `server/src/services/parsers/pdfParser.ts`
- Replace mock `parseDigitalPdf` with PDF.js-based extraction that captures positioned text and heuristically detects columns, categories, and price alignment.
- Fallback: if layout confidence < 0.6, use `pdftotext` to extract text-only and parse heuristically.

2) Scanned PDF Parser (OCR)
- File: `server/src/services/parsers/pdfParser.ts`
- Implement `parseScannedPdf` using `pdftoppm` to rasterize pages and `tesseract.js` for OCR.
- Combine page texts; compute OCR confidence; return parse result.

3) Parser Router
- File: `server/src/services/parseRouter.ts` (new)
- `routeToParser(documentType, mimeType): ParseStrategy` mapping to `pdf_digital` | `pdf_ocr` | `html` | `javascript`.

### Acceptance criteria

- For a digital PDF, the parser returns structured items plus layout metadata.
- For a scanned PDF, OCR runs and returns text that can be analyzed downstream.
- Parser router selects the correct strategy for PDF/HTML types.

---

## Phase 5: Public Endpoint Migration (Unified Pipeline)

### Deliverables

- `server/src/api.ts` public endpoints (`/api/v1/public/upload-menu`, `/api/v1/public/parse-url`):
  - Replace immediate parsing with: triage → enqueue parse → (later) enqueue analysis.
  - Create `documents` rather than writing to `menu_uploads.analysisData`.
  - Keep response shape stable for existing FE, but source data from unified pipeline.

- Remove or deprecate legacy public upload tracking once migrated (`publicUploads`), after data migration.

### Acceptance criteria

- Existing FE continues to function with the same JSON response shapes.
- Public flow uses the same triage/queue/state machine as authenticated flow.

---

## Large Payload Handling (Policy)

- Do not store raw file bytes in DB JSON; store on filesystem and keep a `storagePath` reference.
- Do not return raw file bytes in any API response. Continue stripping `analysisData.fileContent` everywhere; prefer not to store it at all going forward.
- Enforce request size limits:
  - Max upload size (e.g., 10 MB). Return 413 if exceeded.
  - Validate MIME type and reject unsupported types.
- Add basic redaction/sanitization for analysis payloads (omit large raw fields, keep only derived data).

---

## Non-functional & Ops

- Rate limiting: keep existing middleware for public routes; ensure protected routes have reasonable limits.
- Timeouts: set reasonable parse/analysis timeouts to avoid runaway jobs.
- Observability: log job transitions and durations; include `documentId`, `runId` in logs.
- Cleanup: periodic job to remove expired temporary uploads in local storage.

---

## UI Compatibility Notes

- No UI changes required for Phase 2–3; FE should continue to consume menus/analyses without raw file content.
- Audit any `Progress` component props and remove non-supported props (e.g., `color`) in case they surface during refactors.

---

## Step-by-step Task List (checklist)

- [ ] Create `documents`, `parse_runs`, `analysis_runs` tables and migrations; add indexes.
- [ ] Implement `fileStorage.ts` with local FS persistence and add `.gitignore` entry for `server/uploads/`.
- [ ] Implement `documentTriage.ts` with PDF/HTML detection using Poppler tools (system dependency).
- [ ] Introduce `stateMachine.ts` with guarded transitions.
- [ ] Refactor `parseQueue.ts` to operate on `documents` + `parse_runs` only.
- [ ] Create `analysisQueue.ts` for downstream analysis.
- [ ] Add `parseRouter.ts` and wire it into parse queue processing.
- [ ] Replace mock `parseDigitalPdf` with layout-aware implementation; add OCR fallback via `tesseract.js`.
- [ ] Update public endpoints to use triage + queues; keep response shapes.
- [ ] Ensure all API responses omit raw file bytes; cap payload sizes; return 413 for oversize uploads.
- [ ] Add unit/integration tests for triage, state transitions, and queue processing.

---

## Acceptance Test Scenarios

- Upload a digital PDF (authenticated): document created, parse job runs, analysis follows, status transitions valid, UI shows analysis without raw bytes.
- Upload a scanned PDF (authenticated): triage selects OCR path, analysis follows, no raw bytes returned.
- Public upload (URL + file): same unified pipeline; responses unchanged for FE.
- Oversize upload (>10 MB): request rejected with 413.
- Invalid transitions: attempting `parsed → uploaded` fails with clear error.

---

## Environment

- Ensure for local dev:
  - `server/.env` includes `FIREBASE_PROJECT_ID=demo-project` and `FIREBASE_AUTH_EMULATOR_HOST=localhost:5503`.
  - Install Poppler tools: `brew install poppler` (macOS).
  - Optional: `UPLOADS_ROOT` to override local storage directory.
  - Frontend `VITE_API_URL` points to the API (e.g., `http://localhost:5500`).


